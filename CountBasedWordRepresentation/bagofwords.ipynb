{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bagofwords.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMS0WDyI9Nb/5RzoNdTV0wV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/windopper/NerualNetworkPracticeInJupyter/blob/main/CountBasedWordRepresentation/bagofwords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reference https://wikidocs.net/22650"
      ],
      "metadata": {
        "id": "T_rSERr47uL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhKUpphK2fWk",
        "outputId": "85b058ab-2b7d-431d-d483-7792f661b057"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 44.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cPDFya171kMe"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "def build_bag_of_words(document):\n",
        "  # 온점 제거 및 형태소 분석\n",
        "  document = document.replace('.', '')\n",
        "  tokenized_document = okt.morphs(document)\n",
        "\n",
        "  word_to_index = {}\n",
        "  bow = []\n",
        "\n",
        "  for word in tokenized_document:  \n",
        "    if word not in word_to_index.keys():\n",
        "      word_to_index[word] = len(word_to_index)  \n",
        "      # BoW에 전부 기본값 1을 넣는다.\n",
        "      bow.insert(len(word_to_index) - 1, 1)\n",
        "    else:\n",
        "      # 재등장하는 단어의 인덱스\n",
        "      index = word_to_index.get(word)\n",
        "      # 재등장한 단어는 해당하는 인덱스의 위치에 1을 더한다.\n",
        "      bow[index] = bow[index] + 1\n",
        "\n",
        "  return word_to_index, bow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"\n",
        "vocab, bow = build_bag_of_words(doc1)\n",
        "print('vocabulary :', vocab)\n",
        "print('bag of words vector :', bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeVkM74L2nix",
        "outputId": "8588d639-aabd-4fcf-83bc-b21527dfdc2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary : {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
            "bag of words vector : [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "사이킷런의 CountVectorizer클래스로 BoW 만들기"
      ],
      "metadata": {
        "id": "hAvV1e176BmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = ['you know I want  your love, because I love you']\n",
        "vector = CountVectorizer()\n",
        "\n",
        "print('bag of words vector :', vector.fit_transform(corpus).toarray())\n",
        "\n",
        "print('vocabulary :', vector.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTtIS-kf2uup",
        "outputId": "b02c45b5-66d2-4bfa-f3c2-054515db60b5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag of words vector : [[1 1 2 1 2 1]]\n",
            "vocabulary : {'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "불용어를 제거한 BoW 만들기"
      ],
      "metadata": {
        "id": "pw8flxbZ6HS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "nj6mTI3i4-OK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용자 정의 불용어"
      ],
      "metadata": {
        "id": "wf9OwUbu6XHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Family is not an important thing. It's everything.\"]\n",
        "vect = CountVectorizer(stop_words=['the', 'a', 'an', 'is', 'not'])\n",
        "print('bag of words vector :', vect.fit_transform(text).toarray())\n",
        "print('vocabulary :',vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV7iKa3d6WTq",
        "outputId": "35a3a0ca-3f2e-4434-dde0-d21c51ba21e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag of words vector : [[1 1 1 1 1]]\n",
            "vocabulary : {'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer에서 제공하는 자체 불용어"
      ],
      "metadata": {
        "id": "ddTpZI4L6mzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Family is not an important thing. It's everything.\"]\n",
        "vect = CountVectorizer(stop_words=\"english\")\n",
        "print('bag of words vector', vect.fit_transform(text).toarray())\n",
        "print('vocabulary :', vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIFAZAiN6l73",
        "outputId": "57ea04fb-3573-41c2-9499-c30c6f8c065a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag of words vector [[1 1 1]]\n",
            "vocabulary : {'family': 0, 'important': 1, 'thing': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK 에서 지원하는 불용어"
      ],
      "metadata": {
        "id": "wVRUGhGl7AZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Family is not an important thing. It's everything.\"]\n",
        "stop_words = stopwords.words(\"english\")\n",
        "vect = CountVectorizer(stop_words=stop_words)\n",
        "print('bag of words vector :',vect.fit_transform(text).toarray()) \n",
        "print('vocabulary :',vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IEnt7sl67P_",
        "outputId": "3fc11db7-af2c-4e54-eb65-4c812eddcec7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag of words vector : [[1 1 1 1]]\n",
            "vocabulary : {'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uekXP4857PZg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}