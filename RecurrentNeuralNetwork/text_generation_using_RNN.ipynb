{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation_using_RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvmZJ1WedMsfyjWes/la+W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/windopper/NerualNetworkPracticeInJupyter/blob/main/RecurrentNeuralNetwork/text_generation_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN을 이용한 텍스트 생성"
      ],
      "metadata": {
        "id": "Rh8W3O7X1VVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 전처리 과정\n",
        "\n",
        "reference https://wikidocs.net/45101"
      ],
      "metadata": {
        "id": "-kj9bBa21dth"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcz7ORqz1SY_",
        "outputId": "15d4ec0d-4c0d-49b2-8cbd-79f6dbb02425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 12\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
        "그의 말이 법이다\\n\n",
        "가는 말이 고와야 오는 말이 곱다\\n\"\"\"\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "print('단어 집합의 크기 : %d' %vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHjahBrH10YJ",
        "outputId": "a4dd60ff-25e7-4d15-9ef1-f008090bbf8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list()\n",
        "for line in text.split(\"\\n\"):\n",
        "  encoded = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(encoded)):\n",
        "    sequence = encoded[:i+1]\n",
        "    sequences.append(sequence)\n",
        "\n",
        "print('학습에 사용할 샘플의 개수: %d' % len(sequences))\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdZde73U19VT",
        "outputId": "cfd6ec9a-6db0-4daf-9e8f-b906e93050a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습에 사용할 샘플의 개수: 11\n",
            "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 : ', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD5XjdEg2YGk",
        "outputId": "b58bd33d-a83a-4fc6-bfe3-3c9513b94a24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 :  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVJT_Ncd3KiG",
        "outputId": "458ad516-4304-4533-9850-d012ae3caf62"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2  3]\n",
            " [ 0  0  0  2  3  1]\n",
            " [ 0  0  2  3  1  4]\n",
            " [ 0  2  3  1  4  5]\n",
            " [ 0  0  0  0  6  1]\n",
            " [ 0  0  0  6  1  7]\n",
            " [ 0  0  0  0  8  1]\n",
            " [ 0  0  0  8  1  9]\n",
            " [ 0  0  8  1  9 10]\n",
            " [ 0  8  1  9 10  1]\n",
            " [ 8  1  9 10  1 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이블 분리"
      ],
      "metadata": {
        "id": "ge25WVJ53Xpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "x = sequences[:, :-1]\n",
        "y = sequences[:, -1]\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIFEhLM83Pgf",
        "outputId": "e08f0d3a-cbbc-4903-916a-6e8a99a1b4ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2]\n",
            " [ 0  0  0  2  3]\n",
            " [ 0  0  2  3  1]\n",
            " [ 0  2  3  1  4]\n",
            " [ 0  0  0  0  6]\n",
            " [ 0  0  0  6  1]\n",
            " [ 0  0  0  0  8]\n",
            " [ 0  0  0  8  1]\n",
            " [ 0  0  8  1  9]\n",
            " [ 0  8  1  9 10]\n",
            " [ 8  1  9 10  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJlPMSqM3fkq",
        "outputId": "83da9f3d-eadf-4b2f-aee7-cceb13adb0bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이블 분리 완료"
      ],
      "metadata": {
        "id": "F2WjoA-B3hyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이블에 대해서 원-핫 인코딩 수행"
      ],
      "metadata": {
        "id": "zQk8Uvtr3jhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JadRwKr43hPq",
        "outputId": "96cef89b-562d-4d00-8536-951038702f94"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 설계하기"
      ],
      "metadata": {
        "id": "yaUM7Lvs3s5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n"
      ],
      "metadata": {
        "id": "IySf3AuR3q79"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터인 임베딩 벡터의 차원은 10, 은닉 상태의 크기는 32임. 다대일 구조의 RNN을 사용하고 전결합층(FCL)을 출력층으로 단어 집합 크기 만큼의 뉴런을 배치하여 모델을 설계.\n",
        "\n",
        "해당 모델은 마지막 시점에 가능한 단어 중 하나를 예측하는 멀티 클래스 분류 문제 이므로, 출력층에 소프트 맥스 회귀를 사용하고 손실함수로 카테고리얼 크로스 엔트로피 함수를 사용함"
      ],
      "metadata": {
        "id": "prplPZ1u32bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 10\n",
        "hidden_units = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(SimpleRNN(hidden_units))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(x, y, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBEc6Iwa4KY3",
        "outputId": "e6a43e59-71cf-4fa2-92c2-e0858faa20c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 - 5s - loss: 2.4830 - accuracy: 0.2727 - 5s/epoch - 5s/step\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 2.4685 - accuracy: 0.4545 - 22ms/epoch - 22ms/step\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 2.4537 - accuracy: 0.4545 - 29ms/epoch - 29ms/step\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 2.4386 - accuracy: 0.4545 - 39ms/epoch - 39ms/step\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 2.4231 - accuracy: 0.4545 - 26ms/epoch - 26ms/step\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 2.4072 - accuracy: 0.4545 - 31ms/epoch - 31ms/step\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 2.3907 - accuracy: 0.4545 - 46ms/epoch - 46ms/step\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 2.3736 - accuracy: 0.4545 - 64ms/epoch - 64ms/step\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 2.3559 - accuracy: 0.5455 - 40ms/epoch - 40ms/step\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 2.3373 - accuracy: 0.5455 - 33ms/epoch - 33ms/step\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 2.3180 - accuracy: 0.4545 - 45ms/epoch - 45ms/step\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 2.2978 - accuracy: 0.4545 - 24ms/epoch - 24ms/step\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 2.2766 - accuracy: 0.4545 - 46ms/epoch - 46ms/step\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 2.2545 - accuracy: 0.4545 - 38ms/epoch - 38ms/step\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 2.2315 - accuracy: 0.3636 - 52ms/epoch - 52ms/step\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 2.2075 - accuracy: 0.3636 - 42ms/epoch - 42ms/step\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 2.1828 - accuracy: 0.3636 - 38ms/epoch - 38ms/step\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 2.1573 - accuracy: 0.3636 - 40ms/epoch - 40ms/step\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 2.1313 - accuracy: 0.3636 - 33ms/epoch - 33ms/step\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 2.1050 - accuracy: 0.3636 - 35ms/epoch - 35ms/step\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 2.0785 - accuracy: 0.3636 - 32ms/epoch - 32ms/step\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 2.0524 - accuracy: 0.3636 - 28ms/epoch - 28ms/step\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 2.0268 - accuracy: 0.3636 - 21ms/epoch - 21ms/step\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 2.0023 - accuracy: 0.3636 - 21ms/epoch - 21ms/step\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 1.9791 - accuracy: 0.3636 - 34ms/epoch - 34ms/step\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 1.9575 - accuracy: 0.3636 - 24ms/epoch - 24ms/step\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 1.9379 - accuracy: 0.3636 - 31ms/epoch - 31ms/step\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 1.9201 - accuracy: 0.3636 - 31ms/epoch - 31ms/step\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 1.9043 - accuracy: 0.3636 - 48ms/epoch - 48ms/step\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 1.8900 - accuracy: 0.3636 - 47ms/epoch - 47ms/step\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 1.8768 - accuracy: 0.3636 - 35ms/epoch - 35ms/step\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 1.8642 - accuracy: 0.3636 - 52ms/epoch - 52ms/step\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 1.8518 - accuracy: 0.3636 - 33ms/epoch - 33ms/step\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 1.8390 - accuracy: 0.3636 - 48ms/epoch - 48ms/step\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 1.8256 - accuracy: 0.3636 - 57ms/epoch - 57ms/step\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 1.8115 - accuracy: 0.3636 - 27ms/epoch - 27ms/step\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 1.7966 - accuracy: 0.3636 - 40ms/epoch - 40ms/step\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 1.7811 - accuracy: 0.3636 - 50ms/epoch - 50ms/step\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 1.7652 - accuracy: 0.3636 - 24ms/epoch - 24ms/step\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 1.7490 - accuracy: 0.3636 - 45ms/epoch - 45ms/step\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 1.7328 - accuracy: 0.3636 - 43ms/epoch - 43ms/step\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 1.7167 - accuracy: 0.3636 - 41ms/epoch - 41ms/step\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 1.7008 - accuracy: 0.4545 - 33ms/epoch - 33ms/step\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 1.6850 - accuracy: 0.4545 - 28ms/epoch - 28ms/step\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 1.6695 - accuracy: 0.5455 - 39ms/epoch - 39ms/step\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 1.6540 - accuracy: 0.5455 - 32ms/epoch - 32ms/step\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 1.6385 - accuracy: 0.5455 - 41ms/epoch - 41ms/step\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 1.6229 - accuracy: 0.5455 - 39ms/epoch - 39ms/step\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 1.6069 - accuracy: 0.5455 - 30ms/epoch - 30ms/step\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 1.5906 - accuracy: 0.5455 - 32ms/epoch - 32ms/step\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 1.5738 - accuracy: 0.5455 - 67ms/epoch - 67ms/step\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 1.5566 - accuracy: 0.5455 - 46ms/epoch - 46ms/step\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 1.5388 - accuracy: 0.5455 - 37ms/epoch - 37ms/step\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 1.5206 - accuracy: 0.5455 - 35ms/epoch - 35ms/step\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 1.5020 - accuracy: 0.5455 - 27ms/epoch - 27ms/step\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 1.4830 - accuracy: 0.5455 - 27ms/epoch - 27ms/step\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 1.4637 - accuracy: 0.5455 - 46ms/epoch - 46ms/step\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 1.4442 - accuracy: 0.5455 - 30ms/epoch - 30ms/step\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 1.4246 - accuracy: 0.5455 - 35ms/epoch - 35ms/step\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 1.4048 - accuracy: 0.5455 - 43ms/epoch - 43ms/step\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 1.3849 - accuracy: 0.5455 - 59ms/epoch - 59ms/step\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 1.3650 - accuracy: 0.5455 - 38ms/epoch - 38ms/step\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 1.3451 - accuracy: 0.5455 - 43ms/epoch - 43ms/step\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 1.3252 - accuracy: 0.5455 - 32ms/epoch - 32ms/step\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 1.3054 - accuracy: 0.5455 - 46ms/epoch - 46ms/step\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 1.2856 - accuracy: 0.6364 - 38ms/epoch - 38ms/step\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 1.2660 - accuracy: 0.6364 - 41ms/epoch - 41ms/step\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 1.2466 - accuracy: 0.6364 - 63ms/epoch - 63ms/step\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 1.2273 - accuracy: 0.6364 - 36ms/epoch - 36ms/step\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 1.2083 - accuracy: 0.6364 - 40ms/epoch - 40ms/step\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 1.1896 - accuracy: 0.6364 - 36ms/epoch - 36ms/step\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 1.1711 - accuracy: 0.6364 - 32ms/epoch - 32ms/step\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 1.1530 - accuracy: 0.6364 - 29ms/epoch - 29ms/step\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 1.1352 - accuracy: 0.6364 - 27ms/epoch - 27ms/step\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 1.1177 - accuracy: 0.6364 - 27ms/epoch - 27ms/step\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 1.1005 - accuracy: 0.7273 - 26ms/epoch - 26ms/step\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 1.0837 - accuracy: 0.7273 - 34ms/epoch - 34ms/step\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 1.0672 - accuracy: 0.7273 - 37ms/epoch - 37ms/step\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 1.0509 - accuracy: 0.7273 - 33ms/epoch - 33ms/step\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 1.0349 - accuracy: 0.7273 - 37ms/epoch - 37ms/step\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 1.0192 - accuracy: 0.7273 - 29ms/epoch - 29ms/step\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 1.0037 - accuracy: 0.7273 - 43ms/epoch - 43ms/step\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 0.9885 - accuracy: 0.7273 - 34ms/epoch - 34ms/step\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 0.9735 - accuracy: 0.7273 - 54ms/epoch - 54ms/step\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 0.9588 - accuracy: 0.7273 - 29ms/epoch - 29ms/step\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 0.9442 - accuracy: 0.7273 - 27ms/epoch - 27ms/step\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 0.9299 - accuracy: 0.7273 - 34ms/epoch - 34ms/step\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 0.9158 - accuracy: 0.7273 - 26ms/epoch - 26ms/step\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 0.9019 - accuracy: 0.7273 - 40ms/epoch - 40ms/step\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 0.8882 - accuracy: 0.7273 - 39ms/epoch - 39ms/step\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 0.8747 - accuracy: 0.7273 - 24ms/epoch - 24ms/step\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 0.8613 - accuracy: 0.7273 - 34ms/epoch - 34ms/step\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 0.8481 - accuracy: 0.7273 - 31ms/epoch - 31ms/step\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 0.8351 - accuracy: 0.7273 - 22ms/epoch - 22ms/step\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 0.8222 - accuracy: 0.7273 - 28ms/epoch - 28ms/step\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 0.8095 - accuracy: 0.7273 - 21ms/epoch - 21ms/step\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 0.7970 - accuracy: 0.7273 - 34ms/epoch - 34ms/step\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 0.7846 - accuracy: 0.7273 - 38ms/epoch - 38ms/step\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 0.7723 - accuracy: 0.7273 - 40ms/epoch - 40ms/step\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 0.7602 - accuracy: 0.7273 - 31ms/epoch - 31ms/step\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 0.7483 - accuracy: 0.7273 - 45ms/epoch - 45ms/step\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 0.7364 - accuracy: 0.7273 - 38ms/epoch - 38ms/step\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 0.7247 - accuracy: 0.7273 - 42ms/epoch - 42ms/step\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 0.7131 - accuracy: 0.8182 - 44ms/epoch - 44ms/step\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 0.7017 - accuracy: 0.8182 - 37ms/epoch - 37ms/step\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 0.6904 - accuracy: 0.8182 - 63ms/epoch - 63ms/step\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 0.6792 - accuracy: 0.8182 - 47ms/epoch - 47ms/step\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 0.6681 - accuracy: 0.8182 - 31ms/epoch - 31ms/step\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 0.6571 - accuracy: 0.8182 - 37ms/epoch - 37ms/step\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 0.6463 - accuracy: 0.8182 - 46ms/epoch - 46ms/step\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 0.6355 - accuracy: 0.8182 - 24ms/epoch - 24ms/step\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 0.6249 - accuracy: 0.8182 - 29ms/epoch - 29ms/step\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 0.6145 - accuracy: 0.8182 - 32ms/epoch - 32ms/step\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 0.6041 - accuracy: 0.8182 - 25ms/epoch - 25ms/step\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 0.5938 - accuracy: 0.8182 - 31ms/epoch - 31ms/step\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 0.5837 - accuracy: 0.8182 - 39ms/epoch - 39ms/step\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 0.5736 - accuracy: 0.8182 - 39ms/epoch - 39ms/step\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 0.5637 - accuracy: 0.8182 - 57ms/epoch - 57ms/step\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 0.5539 - accuracy: 0.9091 - 36ms/epoch - 36ms/step\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 0.5442 - accuracy: 0.9091 - 20ms/epoch - 20ms/step\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 0.5346 - accuracy: 0.9091 - 36ms/epoch - 36ms/step\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 0.5251 - accuracy: 0.9091 - 26ms/epoch - 26ms/step\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 0.5157 - accuracy: 0.9091 - 28ms/epoch - 28ms/step\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 0.5064 - accuracy: 0.9091 - 22ms/epoch - 22ms/step\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 0.4973 - accuracy: 0.9091 - 19ms/epoch - 19ms/step\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 0.4882 - accuracy: 0.9091 - 23ms/epoch - 23ms/step\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 0.4793 - accuracy: 0.9091 - 41ms/epoch - 41ms/step\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 0.4705 - accuracy: 0.9091 - 25ms/epoch - 25ms/step\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 0.4617 - accuracy: 0.9091 - 22ms/epoch - 22ms/step\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.4531 - accuracy: 0.9091 - 28ms/epoch - 28ms/step\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.4447 - accuracy: 0.9091 - 19ms/epoch - 19ms/step\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.4363 - accuracy: 0.9091 - 29ms/epoch - 29ms/step\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.4280 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.4199 - accuracy: 0.9091 - 29ms/epoch - 29ms/step\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.4119 - accuracy: 0.9091 - 20ms/epoch - 20ms/step\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.4040 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.3962 - accuracy: 0.9091 - 18ms/epoch - 18ms/step\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.3885 - accuracy: 0.9091 - 19ms/epoch - 19ms/step\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.3810 - accuracy: 0.9091 - 23ms/epoch - 23ms/step\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.3736 - accuracy: 0.9091 - 32ms/epoch - 32ms/step\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.3663 - accuracy: 0.9091 - 32ms/epoch - 32ms/step\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.3591 - accuracy: 0.9091 - 27ms/epoch - 27ms/step\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.3521 - accuracy: 0.9091 - 27ms/epoch - 27ms/step\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.3452 - accuracy: 0.9091 - 26ms/epoch - 26ms/step\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.3384 - accuracy: 0.9091 - 19ms/epoch - 19ms/step\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.3318 - accuracy: 0.9091 - 32ms/epoch - 32ms/step\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.3252 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.3188 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.3126 - accuracy: 0.9091 - 28ms/epoch - 28ms/step\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.3064 - accuracy: 0.9091 - 28ms/epoch - 28ms/step\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.3004 - accuracy: 0.9091 - 33ms/epoch - 33ms/step\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.2945 - accuracy: 0.9091 - 23ms/epoch - 23ms/step\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.2887 - accuracy: 0.9091 - 28ms/epoch - 28ms/step\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.2830 - accuracy: 0.9091 - 21ms/epoch - 21ms/step\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.2775 - accuracy: 0.9091 - 26ms/epoch - 26ms/step\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.2721 - accuracy: 0.9091 - 20ms/epoch - 20ms/step\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.2668 - accuracy: 0.9091 - 29ms/epoch - 29ms/step\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.2616 - accuracy: 0.9091 - 37ms/epoch - 37ms/step\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.2565 - accuracy: 0.9091 - 30ms/epoch - 30ms/step\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.2515 - accuracy: 1.0000 - 34ms/epoch - 34ms/step\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.2466 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.2419 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.2372 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.2327 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.2282 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.2239 - accuracy: 1.0000 - 32ms/epoch - 32ms/step\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.2196 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.2155 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.2114 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.2074 - accuracy: 1.0000 - 33ms/epoch - 33ms/step\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.2035 - accuracy: 1.0000 - 29ms/epoch - 29ms/step\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.1997 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.1960 - accuracy: 1.0000 - 29ms/epoch - 29ms/step\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.1924 - accuracy: 1.0000 - 38ms/epoch - 38ms/step\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.1888 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.1853 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.1819 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.1786 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.1753 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.1722 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.1690 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.1660 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.1630 - accuracy: 1.0000 - 29ms/epoch - 29ms/step\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.1601 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.1572 - accuracy: 1.0000 - 30ms/epoch - 30ms/step\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.1544 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.1517 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.1490 - accuracy: 1.0000 - 34ms/epoch - 34ms/step\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.1464 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.1438 - accuracy: 1.0000 - 31ms/epoch - 31ms/step\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.1413 - accuracy: 1.0000 - 36ms/epoch - 36ms/step\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.1389 - accuracy: 1.0000 - 37ms/epoch - 37ms/step\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.1365 - accuracy: 1.0000 - 31ms/epoch - 31ms/step\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.1341 - accuracy: 1.0000 - 40ms/epoch - 40ms/step\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.1318 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.1296 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.1274 - accuracy: 1.0000 - 42ms/epoch - 42ms/step\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.1252 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.1231 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.1210 - accuracy: 1.0000 - 37ms/epoch - 37ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, tokenizer, current_word, n): # 모델 토크나이저 현재 단어 반복할 회수\n",
        "  init_word = current_word\n",
        "  sentence = ''\n",
        "\n",
        "  for _ in range(n):\n",
        "    encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
        "    result = model.predict(encoded, verbose=0)\n",
        "    result = np.argmax(result, axis=1)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == result:\n",
        "        break\n",
        "\n",
        "    current_word = current_word + ' ' + word\n",
        "    sentence = sentence + ' ' + word\n",
        "  sentence = init_word + sentence\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "f-JpyCmA4VLf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '경마장에', 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1-V5rVY5Pkf",
        "outputId": "fe31221b-3a96-4cf1-dfeb-471a9997c8a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "경마장에 있는 말이 뛰고 있다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '그의', 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jOyZEat5UXe",
        "outputId": "85549e35-98e3-463d-f142-fdbd316c823a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "그의 말이 법이다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '가는', 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wqqPMgf5ZND",
        "outputId": "8ed139d7-23ba-4bf1-cd4e-193afed07081"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가는 말이 고와야 오는 말이 곱다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], 'b-', label='accuracy')\n",
        "plt.plot(history.history['loss'], 'r-', label='loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "fJHtx2C-6UsZ",
        "outputId": "61fdadef-57cb-4e41-9e17-d99e47f91b76"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM을 이용하여 텍스트 생성하기\n",
        "\n",
        "뉴욕 타임즈 기사 데이터 사용하기"
      ],
      "metadata": {
        "id": "T_SbDfYI7cvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from google.colab import files\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "upload = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "bLwGcmms6meH",
        "outputId": "913dd88d-e254-4e25-de29-8b91f56f08a5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-34809d24-bf46-48e0-83e9-b48574c412c8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-34809d24-bf46-48e0-83e9-b48574c412c8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ArticlesApril2018.csv to ArticlesApril2018 (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('ArticlesApril2018.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "AUssuq9z8VJg",
        "outputId": "9a0947f4-7cf7-418f-feb6-94ddccd553b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-63715425-b093-4ee2-96b4-43dd83da4cee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articleID</th>\n",
              "      <th>articleWordCount</th>\n",
              "      <th>byline</th>\n",
              "      <th>documentType</th>\n",
              "      <th>headline</th>\n",
              "      <th>keywords</th>\n",
              "      <th>multimedia</th>\n",
              "      <th>newDesk</th>\n",
              "      <th>printPage</th>\n",
              "      <th>pubDate</th>\n",
              "      <th>sectionName</th>\n",
              "      <th>snippet</th>\n",
              "      <th>source</th>\n",
              "      <th>typeOfMaterial</th>\n",
              "      <th>webURL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5adf6684068401528a2aa69b</td>\n",
              "      <td>781</td>\n",
              "      <td>By JOHN BRANCH</td>\n",
              "      <td>article</td>\n",
              "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
              "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
              "      <td>68</td>\n",
              "      <td>Sports</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:16:49</td>\n",
              "      <td>Pro Football</td>\n",
              "      <td>“I understand that they could meet with us, pa...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5adf653f068401528a2aa697</td>\n",
              "      <td>656</td>\n",
              "      <td>By LISA FRIEDMAN</td>\n",
              "      <td>article</td>\n",
              "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
              "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
              "      <td>68</td>\n",
              "      <td>Climate</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:11:21</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>The agency plans to publish a new regulation T...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5adf4626068401528a2aa628</td>\n",
              "      <td>2427</td>\n",
              "      <td>By PETE WELLS</td>\n",
              "      <td>article</td>\n",
              "      <td>The New Noma, Explained</td>\n",
              "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
              "      <td>66</td>\n",
              "      <td>Dining</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:58:44</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>What’s it like to eat at the second incarnatio...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5adf40d2068401528a2aa619</td>\n",
              "      <td>626</td>\n",
              "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
              "      <td>68</td>\n",
              "      <td>Washington</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:35:57</td>\n",
              "      <td>Europe</td>\n",
              "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5adf3d64068401528a2aa60f</td>\n",
              "      <td>815</td>\n",
              "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
              "      <td>68</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:21:21</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63715425-b093-4ee2-96b4-43dd83da4cee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63715425-b093-4ee2-96b4-43dd83da4cee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63715425-b093-4ee2-96b4-43dd83da4cee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  articleID  ...                                             webURL\n",
              "0  5adf6684068401528a2aa69b  ...  https://www.nytimes.com/2018/04/24/sports/foot...\n",
              "1  5adf653f068401528a2aa697  ...  https://www.nytimes.com/2018/04/24/climate/epa...\n",
              "2  5adf4626068401528a2aa628  ...  https://www.nytimes.com/2018/04/24/dining/noma...\n",
              "3  5adf40d2068401528a2aa619  ...  https://www.nytimes.com/2018/04/24/world/europ...\n",
              "4  5adf3d64068401528a2aa60f  ...  https://www.nytimes.com/2018/04/24/world/canad...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('열의 개수 : ', len(df.columns))\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5GrnagQ81DB",
        "outputId": "67f20b23-0954-44d9-d643-e5a1bde4044f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "열의 개수 :  15\n",
            "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
            "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
            "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['headline'].isnull().values.any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmPgx7wf85nt",
        "outputId": "c75cd6ae-2551-423e-cce5-4da34289f25a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "헤드라인을 별도의 리스트로 저장"
      ],
      "metadata": {
        "id": "_6oF6Pgk9EBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headline = []\n",
        "\n",
        "headline.extend(list(df.headline.values))\n",
        "headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFUPutDO9Bsp",
        "outputId": "4b1b5c19-e03d-432a-852d-b962a4cc6cad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'Unknown',\n",
              " 'Unknown']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "headline 전체에 unknown 값이 들어간 샘플이 있는 것으로 파악되어 그 노이즈데이터를 제거해줄 필요가 있음"
      ],
      "metadata": {
        "id": "_14_2yr39WEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(headline))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s86Ki08h9KgT",
        "outputId": "45dcd837-40cf-4cd0-b615-0ffd1f64887f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headline = [ word for word in headline if word != \"Unknown\"]\n",
        "print(len(headline))\n",
        "headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oweYmfaz9gt5",
        "outputId": "33833afd-8e73-4953-ae46-3459f2daa162"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1214\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
              " 'Is School a Place for Self-Expression?']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "110개의 샘플이 제거됨"
      ],
      "metadata": {
        "id": "tFfDYjiG9wkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리 수행 작업\n",
        "\n",
        "구두점 제거과 단어의 소문자화를 시행"
      ],
      "metadata": {
        "id": "4SrZi4gc9zzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def repreprocessing(raw_sentence):\n",
        "  preprocessed_sentence = raw_sentence.encode('utf-8').decode('ascii', 'ignore')\n",
        "  return ''.join(word for word in preprocessed_sentence if word not in punctuation).lower()\n",
        "\n",
        "preprocessed_headline = [repreprocessing(x) for x in headline]\n",
        "preprocessed_headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zVfv8ia9vMp",
        "outputId": "64c56ec3-0982-4328-c835-440894834c0a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
              " 'epa to unveil a new rule its effect less science in policymaking',\n",
              " 'the new noma explained',\n",
              " 'how a bag of texas dirt  became a times tradition',\n",
              " 'is school a place for selfexpression']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전과 비교하면 모든 단어들이 소문자화 되었으면 N.F.L이나 Cheerleaders' 와 같이 구두점이 들어있었던 단어들에서 구두점이 제거됨"
      ],
      "metadata": {
        "id": "7VIU95iu-X14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 단어 집합을 만들면"
      ],
      "metadata": {
        "id": "kb_PfLo9-ge3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_headline)\n",
        "vocab_size = len(tokenizer.index_word) + 1\n",
        "print('단어 집합의 크기 : ', vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pryhzLA963r",
        "outputId": "dbbeefcd-fc6f-49fc-a54d-5f08b3abb95a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 :  3494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정수 인코딩을 진행하는 동시에 문장을 여러줄로 분해하여 훈련 데이터 구성"
      ],
      "metadata": {
        "id": "ctAaKBHT-4EJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list()\n",
        "\n",
        "for sentence in preprocessed_headline:\n",
        "  encoded = tokenizer.texts_to_sequences([sentence])[0]\n",
        "  for i in range(1, len(encoded)):\n",
        "    sequence = encoded[:i+1]\n",
        "    sequences.append(sequence)\n",
        "\n",
        "sequences[:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlGUkl57-y1z",
        "outputId": "6a22b568-511a-4e4e-e347-06c85466b415"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[99, 269],\n",
              " [99, 269, 371],\n",
              " [99, 269, 371, 1115],\n",
              " [99, 269, 371, 1115, 582],\n",
              " [99, 269, 371, 1115, 582, 52],\n",
              " [99, 269, 371, 1115, 582, 52, 7],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
              " [100, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "인덱스를 단어로 바꾸기 위한 index_to_word를 만들면"
      ],
      "metadata": {
        "id": "dAoqr-dA_3Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {}\n",
        "\n",
        "for key, value in tokenizer.word_index.items():\n",
        "  index_to_word[value] = key\n",
        "\n",
        "print('빈도수 상위 582번 단어 : {}'.format(index_to_word[582]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D7_8Jlc_c_D",
        "outputId": "eebb1688-a419-49b3-d736-78d93ada284f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빈도수 상위 582번 단어 : offer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 샘플의 길이를 동일하게 맞추는 패딩 작업을 시행"
      ],
      "metadata": {
        "id": "ua8kQcF7AUWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 : ', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cobLyQwtAOiM",
        "outputId": "062d0cd8-6d30-4756-8e3a-40025b991cac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 :  24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "print(sequences[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOBfYydJAc5r",
        "outputId": "2182cdb8-42eb-4687-fec0-867e11057b7d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0   99  269]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0   99  269  371]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0   99  269  371 1115]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0   99  269  371 1115  582]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0   99  269  371 1115  582   52]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "맨 우측 단어만 레이블로 분리하면"
      ],
      "metadata": {
        "id": "6iGHGU-pAnw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "x = sequences[:, :-1]\n",
        "y = sequences[:, -1]\n",
        "\n",
        "print(x[:5])\n",
        "print(y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnc6tkb8AlSU",
        "outputId": "2bc17313-360d-4fef-9c86-0f154a4e9369"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0   99]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0   99  269]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0   99  269  371]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0   99  269  371 1115]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0   99  269  371 1115  582]]\n",
            "[ 269  371 1115  582   52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "y 레이블에 대해서 원-핫 인코딩 수행"
      ],
      "metadata": {
        "id": "tJhohkgvA2sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "print(y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqxg4pWqAz4V",
        "outputId": "90d6904d-7e07-4eea-bbe5-7590f756712d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 설계하기"
      ],
      "metadata": {
        "id": "aJ2x2MyhJJ9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "embedding_dim = 10\n",
        "hidden_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(LSTM(hidden_units))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x, y, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxhg1tTTA7TO",
        "outputId": "26d43b7b-a4cc-4e00-a672-b357673ada06"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "244/244 - 11s - loss: 7.6475 - accuracy: 0.0291 - 11s/epoch - 45ms/step\n",
            "Epoch 2/200\n",
            "244/244 - 3s - loss: 7.1113 - accuracy: 0.0304 - 3s/epoch - 13ms/step\n",
            "Epoch 3/200\n",
            "244/244 - 3s - loss: 6.9725 - accuracy: 0.0346 - 3s/epoch - 13ms/step\n",
            "Epoch 4/200\n",
            "244/244 - 3s - loss: 6.8455 - accuracy: 0.0397 - 3s/epoch - 13ms/step\n",
            "Epoch 5/200\n",
            "244/244 - 3s - loss: 6.6941 - accuracy: 0.0452 - 3s/epoch - 13ms/step\n",
            "Epoch 6/200\n",
            "244/244 - 3s - loss: 6.5270 - accuracy: 0.0482 - 3s/epoch - 13ms/step\n",
            "Epoch 7/200\n",
            "244/244 - 3s - loss: 6.3380 - accuracy: 0.0499 - 3s/epoch - 13ms/step\n",
            "Epoch 8/200\n",
            "244/244 - 3s - loss: 6.1422 - accuracy: 0.0565 - 3s/epoch - 13ms/step\n",
            "Epoch 9/200\n",
            "244/244 - 3s - loss: 5.9514 - accuracy: 0.0610 - 3s/epoch - 13ms/step\n",
            "Epoch 10/200\n",
            "244/244 - 3s - loss: 5.7655 - accuracy: 0.0668 - 3s/epoch - 13ms/step\n",
            "Epoch 11/200\n",
            "244/244 - 3s - loss: 5.5937 - accuracy: 0.0693 - 3s/epoch - 14ms/step\n",
            "Epoch 12/200\n",
            "244/244 - 3s - loss: 5.4321 - accuracy: 0.0714 - 3s/epoch - 14ms/step\n",
            "Epoch 13/200\n",
            "244/244 - 3s - loss: 5.2795 - accuracy: 0.0823 - 3s/epoch - 13ms/step\n",
            "Epoch 14/200\n",
            "244/244 - 3s - loss: 5.1315 - accuracy: 0.0866 - 3s/epoch - 13ms/step\n",
            "Epoch 15/200\n",
            "244/244 - 3s - loss: 4.9950 - accuracy: 0.0951 - 3s/epoch - 14ms/step\n",
            "Epoch 16/200\n",
            "244/244 - 3s - loss: 4.8597 - accuracy: 0.1034 - 3s/epoch - 12ms/step\n",
            "Epoch 17/200\n",
            "244/244 - 3s - loss: 4.7323 - accuracy: 0.1132 - 3s/epoch - 12ms/step\n",
            "Epoch 18/200\n",
            "244/244 - 3s - loss: 4.6091 - accuracy: 0.1288 - 3s/epoch - 13ms/step\n",
            "Epoch 19/200\n",
            "244/244 - 3s - loss: 4.4860 - accuracy: 0.1425 - 3s/epoch - 13ms/step\n",
            "Epoch 20/200\n",
            "244/244 - 3s - loss: 4.3726 - accuracy: 0.1540 - 3s/epoch - 13ms/step\n",
            "Epoch 21/200\n",
            "244/244 - 3s - loss: 4.2608 - accuracy: 0.1729 - 3s/epoch - 12ms/step\n",
            "Epoch 22/200\n",
            "244/244 - 3s - loss: 4.1510 - accuracy: 0.1865 - 3s/epoch - 13ms/step\n",
            "Epoch 23/200\n",
            "244/244 - 3s - loss: 4.0451 - accuracy: 0.2070 - 3s/epoch - 12ms/step\n",
            "Epoch 24/200\n",
            "244/244 - 3s - loss: 3.9422 - accuracy: 0.2172 - 3s/epoch - 12ms/step\n",
            "Epoch 25/200\n",
            "244/244 - 3s - loss: 3.8441 - accuracy: 0.2384 - 3s/epoch - 13ms/step\n",
            "Epoch 26/200\n",
            "244/244 - 3s - loss: 3.7448 - accuracy: 0.2537 - 3s/epoch - 13ms/step\n",
            "Epoch 27/200\n",
            "244/244 - 3s - loss: 3.6538 - accuracy: 0.2707 - 3s/epoch - 12ms/step\n",
            "Epoch 28/200\n",
            "244/244 - 3s - loss: 3.5640 - accuracy: 0.2851 - 3s/epoch - 14ms/step\n",
            "Epoch 29/200\n",
            "244/244 - 3s - loss: 3.4770 - accuracy: 0.3017 - 3s/epoch - 14ms/step\n",
            "Epoch 30/200\n",
            "244/244 - 3s - loss: 3.3921 - accuracy: 0.3153 - 3s/epoch - 12ms/step\n",
            "Epoch 31/200\n",
            "244/244 - 3s - loss: 3.3091 - accuracy: 0.3405 - 3s/epoch - 14ms/step\n",
            "Epoch 32/200\n",
            "244/244 - 3s - loss: 3.2280 - accuracy: 0.3468 - 3s/epoch - 12ms/step\n",
            "Epoch 33/200\n",
            "244/244 - 3s - loss: 3.1548 - accuracy: 0.3614 - 3s/epoch - 13ms/step\n",
            "Epoch 34/200\n",
            "244/244 - 3s - loss: 3.0809 - accuracy: 0.3777 - 3s/epoch - 12ms/step\n",
            "Epoch 35/200\n",
            "244/244 - 3s - loss: 3.0105 - accuracy: 0.3877 - 3s/epoch - 13ms/step\n",
            "Epoch 36/200\n",
            "244/244 - 3s - loss: 2.9412 - accuracy: 0.4009 - 3s/epoch - 13ms/step\n",
            "Epoch 37/200\n",
            "244/244 - 3s - loss: 2.8742 - accuracy: 0.4123 - 3s/epoch - 12ms/step\n",
            "Epoch 38/200\n",
            "244/244 - 3s - loss: 2.8102 - accuracy: 0.4243 - 3s/epoch - 12ms/step\n",
            "Epoch 39/200\n",
            "244/244 - 3s - loss: 2.7469 - accuracy: 0.4393 - 3s/epoch - 12ms/step\n",
            "Epoch 40/200\n",
            "244/244 - 3s - loss: 2.6859 - accuracy: 0.4498 - 3s/epoch - 11ms/step\n",
            "Epoch 41/200\n",
            "244/244 - 3s - loss: 2.6265 - accuracy: 0.4602 - 3s/epoch - 12ms/step\n",
            "Epoch 42/200\n",
            "244/244 - 3s - loss: 2.5735 - accuracy: 0.4701 - 3s/epoch - 13ms/step\n",
            "Epoch 43/200\n",
            "244/244 - 3s - loss: 2.5171 - accuracy: 0.4798 - 3s/epoch - 13ms/step\n",
            "Epoch 44/200\n",
            "244/244 - 3s - loss: 2.4598 - accuracy: 0.4899 - 3s/epoch - 12ms/step\n",
            "Epoch 45/200\n",
            "244/244 - 3s - loss: 2.4133 - accuracy: 0.5035 - 3s/epoch - 12ms/step\n",
            "Epoch 46/200\n",
            "244/244 - 3s - loss: 2.3604 - accuracy: 0.5089 - 3s/epoch - 13ms/step\n",
            "Epoch 47/200\n",
            "244/244 - 3s - loss: 2.3111 - accuracy: 0.5183 - 3s/epoch - 12ms/step\n",
            "Epoch 48/200\n",
            "244/244 - 2s - loss: 2.2621 - accuracy: 0.5331 - 2s/epoch - 10ms/step\n",
            "Epoch 49/200\n",
            "244/244 - 2s - loss: 2.2156 - accuracy: 0.5404 - 2s/epoch - 10ms/step\n",
            "Epoch 50/200\n",
            "244/244 - 2s - loss: 2.1693 - accuracy: 0.5522 - 2s/epoch - 10ms/step\n",
            "Epoch 51/200\n",
            "244/244 - 2s - loss: 2.1225 - accuracy: 0.5597 - 2s/epoch - 9ms/step\n",
            "Epoch 52/200\n",
            "244/244 - 2s - loss: 2.0780 - accuracy: 0.5749 - 2s/epoch - 9ms/step\n",
            "Epoch 53/200\n",
            "244/244 - 2s - loss: 2.0339 - accuracy: 0.5790 - 2s/epoch - 9ms/step\n",
            "Epoch 54/200\n",
            "244/244 - 2s - loss: 1.9942 - accuracy: 0.5882 - 2s/epoch - 9ms/step\n",
            "Epoch 55/200\n",
            "244/244 - 2s - loss: 1.9521 - accuracy: 0.5950 - 2s/epoch - 9ms/step\n",
            "Epoch 56/200\n",
            "244/244 - 2s - loss: 1.9135 - accuracy: 0.6030 - 2s/epoch - 9ms/step\n",
            "Epoch 57/200\n",
            "244/244 - 2s - loss: 1.8730 - accuracy: 0.6150 - 2s/epoch - 9ms/step\n",
            "Epoch 58/200\n",
            "244/244 - 2s - loss: 1.8329 - accuracy: 0.6209 - 2s/epoch - 9ms/step\n",
            "Epoch 59/200\n",
            "244/244 - 2s - loss: 1.7951 - accuracy: 0.6292 - 2s/epoch - 9ms/step\n",
            "Epoch 60/200\n",
            "244/244 - 2s - loss: 1.7535 - accuracy: 0.6419 - 2s/epoch - 9ms/step\n",
            "Epoch 61/200\n",
            "244/244 - 2s - loss: 1.7201 - accuracy: 0.6503 - 2s/epoch - 9ms/step\n",
            "Epoch 62/200\n",
            "244/244 - 2s - loss: 1.6816 - accuracy: 0.6581 - 2s/epoch - 9ms/step\n",
            "Epoch 63/200\n",
            "244/244 - 2s - loss: 1.6471 - accuracy: 0.6637 - 2s/epoch - 9ms/step\n",
            "Epoch 64/200\n",
            "244/244 - 2s - loss: 1.6084 - accuracy: 0.6777 - 2s/epoch - 9ms/step\n",
            "Epoch 65/200\n",
            "244/244 - 2s - loss: 1.5748 - accuracy: 0.6828 - 2s/epoch - 9ms/step\n",
            "Epoch 66/200\n",
            "244/244 - 2s - loss: 1.5400 - accuracy: 0.6886 - 2s/epoch - 9ms/step\n",
            "Epoch 67/200\n",
            "244/244 - 2s - loss: 1.5081 - accuracy: 0.6976 - 2s/epoch - 9ms/step\n",
            "Epoch 68/200\n",
            "244/244 - 2s - loss: 1.4743 - accuracy: 0.7033 - 2s/epoch - 9ms/step\n",
            "Epoch 69/200\n",
            "244/244 - 2s - loss: 1.4427 - accuracy: 0.7128 - 2s/epoch - 9ms/step\n",
            "Epoch 70/200\n",
            "244/244 - 2s - loss: 1.4099 - accuracy: 0.7190 - 2s/epoch - 9ms/step\n",
            "Epoch 71/200\n",
            "244/244 - 2s - loss: 1.3803 - accuracy: 0.7274 - 2s/epoch - 9ms/step\n",
            "Epoch 72/200\n",
            "244/244 - 2s - loss: 1.3489 - accuracy: 0.7288 - 2s/epoch - 9ms/step\n",
            "Epoch 73/200\n",
            "244/244 - 2s - loss: 1.3191 - accuracy: 0.7368 - 2s/epoch - 9ms/step\n",
            "Epoch 74/200\n",
            "244/244 - 2s - loss: 1.2895 - accuracy: 0.7437 - 2s/epoch - 9ms/step\n",
            "Epoch 75/200\n",
            "244/244 - 2s - loss: 1.2600 - accuracy: 0.7529 - 2s/epoch - 9ms/step\n",
            "Epoch 76/200\n",
            "244/244 - 2s - loss: 1.2326 - accuracy: 0.7547 - 2s/epoch - 9ms/step\n",
            "Epoch 77/200\n",
            "244/244 - 2s - loss: 1.2042 - accuracy: 0.7677 - 2s/epoch - 9ms/step\n",
            "Epoch 78/200\n",
            "244/244 - 2s - loss: 1.1790 - accuracy: 0.7679 - 2s/epoch - 9ms/step\n",
            "Epoch 79/200\n",
            "244/244 - 2s - loss: 1.1506 - accuracy: 0.7715 - 2s/epoch - 9ms/step\n",
            "Epoch 80/200\n",
            "244/244 - 2s - loss: 1.1258 - accuracy: 0.7739 - 2s/epoch - 10ms/step\n",
            "Epoch 81/200\n",
            "244/244 - 2s - loss: 1.1004 - accuracy: 0.7823 - 2s/epoch - 10ms/step\n",
            "Epoch 82/200\n",
            "244/244 - 2s - loss: 1.0754 - accuracy: 0.7883 - 2s/epoch - 9ms/step\n",
            "Epoch 83/200\n",
            "244/244 - 2s - loss: 1.0505 - accuracy: 0.7925 - 2s/epoch - 9ms/step\n",
            "Epoch 84/200\n",
            "244/244 - 2s - loss: 1.0271 - accuracy: 0.7939 - 2s/epoch - 9ms/step\n",
            "Epoch 85/200\n",
            "244/244 - 2s - loss: 1.0040 - accuracy: 0.8007 - 2s/epoch - 9ms/step\n",
            "Epoch 86/200\n",
            "244/244 - 2s - loss: 0.9804 - accuracy: 0.8048 - 2s/epoch - 9ms/step\n",
            "Epoch 87/200\n",
            "244/244 - 2s - loss: 0.9597 - accuracy: 0.8105 - 2s/epoch - 9ms/step\n",
            "Epoch 88/200\n",
            "244/244 - 2s - loss: 0.9360 - accuracy: 0.8140 - 2s/epoch - 9ms/step\n",
            "Epoch 89/200\n",
            "244/244 - 2s - loss: 0.9160 - accuracy: 0.8196 - 2s/epoch - 9ms/step\n",
            "Epoch 90/200\n",
            "244/244 - 2s - loss: 0.8964 - accuracy: 0.8198 - 2s/epoch - 9ms/step\n",
            "Epoch 91/200\n",
            "244/244 - 2s - loss: 0.8767 - accuracy: 0.8263 - 2s/epoch - 9ms/step\n",
            "Epoch 92/200\n",
            "244/244 - 2s - loss: 0.8560 - accuracy: 0.8302 - 2s/epoch - 9ms/step\n",
            "Epoch 93/200\n",
            "244/244 - 2s - loss: 0.8367 - accuracy: 0.8360 - 2s/epoch - 9ms/step\n",
            "Epoch 94/200\n",
            "244/244 - 2s - loss: 0.8175 - accuracy: 0.8369 - 2s/epoch - 9ms/step\n",
            "Epoch 95/200\n",
            "244/244 - 2s - loss: 0.8003 - accuracy: 0.8415 - 2s/epoch - 9ms/step\n",
            "Epoch 96/200\n",
            "244/244 - 2s - loss: 0.7832 - accuracy: 0.8457 - 2s/epoch - 9ms/step\n",
            "Epoch 97/200\n",
            "244/244 - 2s - loss: 0.7652 - accuracy: 0.8504 - 2s/epoch - 9ms/step\n",
            "Epoch 98/200\n",
            "244/244 - 2s - loss: 0.7496 - accuracy: 0.8476 - 2s/epoch - 9ms/step\n",
            "Epoch 99/200\n",
            "244/244 - 2s - loss: 0.7319 - accuracy: 0.8533 - 2s/epoch - 9ms/step\n",
            "Epoch 100/200\n",
            "244/244 - 2s - loss: 0.7158 - accuracy: 0.8580 - 2s/epoch - 9ms/step\n",
            "Epoch 101/200\n",
            "244/244 - 2s - loss: 0.7014 - accuracy: 0.8603 - 2s/epoch - 9ms/step\n",
            "Epoch 102/200\n",
            "244/244 - 2s - loss: 0.6889 - accuracy: 0.8620 - 2s/epoch - 9ms/step\n",
            "Epoch 103/200\n",
            "244/244 - 3s - loss: 0.6757 - accuracy: 0.8661 - 3s/epoch - 11ms/step\n",
            "Epoch 104/200\n",
            "244/244 - 3s - loss: 0.6572 - accuracy: 0.8707 - 3s/epoch - 11ms/step\n",
            "Epoch 105/200\n",
            "244/244 - 3s - loss: 0.6425 - accuracy: 0.8724 - 3s/epoch - 11ms/step\n",
            "Epoch 106/200\n",
            "244/244 - 3s - loss: 0.6307 - accuracy: 0.8734 - 3s/epoch - 12ms/step\n",
            "Epoch 107/200\n",
            "244/244 - 3s - loss: 0.6152 - accuracy: 0.8770 - 3s/epoch - 11ms/step\n",
            "Epoch 108/200\n",
            "244/244 - 3s - loss: 0.6038 - accuracy: 0.8803 - 3s/epoch - 13ms/step\n",
            "Epoch 109/200\n",
            "244/244 - 3s - loss: 0.5919 - accuracy: 0.8811 - 3s/epoch - 12ms/step\n",
            "Epoch 110/200\n",
            "244/244 - 3s - loss: 0.5804 - accuracy: 0.8836 - 3s/epoch - 11ms/step\n",
            "Epoch 111/200\n",
            "244/244 - 3s - loss: 0.5698 - accuracy: 0.8862 - 3s/epoch - 12ms/step\n",
            "Epoch 112/200\n",
            "244/244 - 3s - loss: 0.5567 - accuracy: 0.8875 - 3s/epoch - 12ms/step\n",
            "Epoch 113/200\n",
            "244/244 - 3s - loss: 0.5473 - accuracy: 0.8906 - 3s/epoch - 10ms/step\n",
            "Epoch 114/200\n",
            "244/244 - 3s - loss: 0.5361 - accuracy: 0.8885 - 3s/epoch - 11ms/step\n",
            "Epoch 115/200\n",
            "244/244 - 3s - loss: 0.5241 - accuracy: 0.8934 - 3s/epoch - 12ms/step\n",
            "Epoch 116/200\n",
            "244/244 - 3s - loss: 0.5138 - accuracy: 0.8948 - 3s/epoch - 12ms/step\n",
            "Epoch 117/200\n",
            "244/244 - 3s - loss: 0.5055 - accuracy: 0.8977 - 3s/epoch - 12ms/step\n",
            "Epoch 118/200\n",
            "244/244 - 3s - loss: 0.4959 - accuracy: 0.8966 - 3s/epoch - 10ms/step\n",
            "Epoch 119/200\n",
            "244/244 - 2s - loss: 0.4866 - accuracy: 0.9006 - 2s/epoch - 10ms/step\n",
            "Epoch 120/200\n",
            "244/244 - 2s - loss: 0.4760 - accuracy: 0.9025 - 2s/epoch - 9ms/step\n",
            "Epoch 121/200\n",
            "244/244 - 2s - loss: 0.4678 - accuracy: 0.9023 - 2s/epoch - 9ms/step\n",
            "Epoch 122/200\n",
            "244/244 - 2s - loss: 0.4595 - accuracy: 0.9025 - 2s/epoch - 9ms/step\n",
            "Epoch 123/200\n",
            "244/244 - 3s - loss: 0.4527 - accuracy: 0.9036 - 3s/epoch - 10ms/step\n",
            "Epoch 124/200\n",
            "244/244 - 3s - loss: 0.4449 - accuracy: 0.9052 - 3s/epoch - 11ms/step\n",
            "Epoch 125/200\n",
            "244/244 - 3s - loss: 0.4373 - accuracy: 0.9075 - 3s/epoch - 11ms/step\n",
            "Epoch 126/200\n",
            "244/244 - 3s - loss: 0.4337 - accuracy: 0.9067 - 3s/epoch - 10ms/step\n",
            "Epoch 127/200\n",
            "244/244 - 3s - loss: 0.4235 - accuracy: 0.9070 - 3s/epoch - 10ms/step\n",
            "Epoch 128/200\n",
            "244/244 - 3s - loss: 0.4142 - accuracy: 0.9090 - 3s/epoch - 12ms/step\n",
            "Epoch 129/200\n",
            "244/244 - 3s - loss: 0.4085 - accuracy: 0.9098 - 3s/epoch - 12ms/step\n",
            "Epoch 130/200\n",
            "244/244 - 3s - loss: 0.4041 - accuracy: 0.9084 - 3s/epoch - 12ms/step\n",
            "Epoch 131/200\n",
            "244/244 - 3s - loss: 0.3987 - accuracy: 0.9089 - 3s/epoch - 12ms/step\n",
            "Epoch 132/200\n",
            "244/244 - 3s - loss: 0.3937 - accuracy: 0.9107 - 3s/epoch - 12ms/step\n",
            "Epoch 133/200\n",
            "244/244 - 3s - loss: 0.3859 - accuracy: 0.9102 - 3s/epoch - 13ms/step\n",
            "Epoch 134/200\n",
            "244/244 - 3s - loss: 0.3798 - accuracy: 0.9116 - 3s/epoch - 13ms/step\n",
            "Epoch 135/200\n",
            "244/244 - 3s - loss: 0.3752 - accuracy: 0.9116 - 3s/epoch - 12ms/step\n",
            "Epoch 136/200\n",
            "244/244 - 3s - loss: 0.3698 - accuracy: 0.9132 - 3s/epoch - 12ms/step\n",
            "Epoch 137/200\n",
            "244/244 - 3s - loss: 0.3651 - accuracy: 0.9126 - 3s/epoch - 12ms/step\n",
            "Epoch 138/200\n",
            "244/244 - 3s - loss: 0.3635 - accuracy: 0.9129 - 3s/epoch - 12ms/step\n",
            "Epoch 139/200\n",
            "244/244 - 3s - loss: 0.3629 - accuracy: 0.9143 - 3s/epoch - 13ms/step\n",
            "Epoch 140/200\n",
            "244/244 - 3s - loss: 0.3731 - accuracy: 0.9086 - 3s/epoch - 13ms/step\n",
            "Epoch 141/200\n",
            "244/244 - 3s - loss: 0.3553 - accuracy: 0.9123 - 3s/epoch - 13ms/step\n",
            "Epoch 142/200\n",
            "244/244 - 3s - loss: 0.3472 - accuracy: 0.9157 - 3s/epoch - 12ms/step\n",
            "Epoch 143/200\n",
            "244/244 - 3s - loss: 0.3428 - accuracy: 0.9139 - 3s/epoch - 11ms/step\n",
            "Epoch 144/200\n",
            "244/244 - 3s - loss: 0.3428 - accuracy: 0.9125 - 3s/epoch - 12ms/step\n",
            "Epoch 145/200\n",
            "244/244 - 3s - loss: 0.3394 - accuracy: 0.9157 - 3s/epoch - 12ms/step\n",
            "Epoch 146/200\n",
            "244/244 - 2s - loss: 0.3323 - accuracy: 0.9134 - 2s/epoch - 10ms/step\n",
            "Epoch 147/200\n",
            "244/244 - 2s - loss: 0.3286 - accuracy: 0.9161 - 2s/epoch - 9ms/step\n",
            "Epoch 148/200\n",
            "244/244 - 2s - loss: 0.3260 - accuracy: 0.9139 - 2s/epoch - 9ms/step\n",
            "Epoch 149/200\n",
            "244/244 - 2s - loss: 0.3212 - accuracy: 0.9150 - 2s/epoch - 9ms/step\n",
            "Epoch 150/200\n",
            "244/244 - 2s - loss: 0.3188 - accuracy: 0.9145 - 2s/epoch - 9ms/step\n",
            "Epoch 151/200\n",
            "244/244 - 2s - loss: 0.3157 - accuracy: 0.9148 - 2s/epoch - 9ms/step\n",
            "Epoch 152/200\n",
            "244/244 - 2s - loss: 0.3148 - accuracy: 0.9166 - 2s/epoch - 9ms/step\n",
            "Epoch 153/200\n",
            "244/244 - 2s - loss: 0.3128 - accuracy: 0.9150 - 2s/epoch - 9ms/step\n",
            "Epoch 154/200\n",
            "244/244 - 2s - loss: 0.3103 - accuracy: 0.9161 - 2s/epoch - 9ms/step\n",
            "Epoch 155/200\n",
            "244/244 - 2s - loss: 0.3064 - accuracy: 0.9162 - 2s/epoch - 9ms/step\n",
            "Epoch 156/200\n",
            "244/244 - 2s - loss: 0.3055 - accuracy: 0.9163 - 2s/epoch - 9ms/step\n",
            "Epoch 157/200\n",
            "244/244 - 2s - loss: 0.3031 - accuracy: 0.9157 - 2s/epoch - 9ms/step\n",
            "Epoch 158/200\n",
            "244/244 - 2s - loss: 0.3074 - accuracy: 0.9170 - 2s/epoch - 9ms/step\n",
            "Epoch 159/200\n",
            "244/244 - 2s - loss: 0.3197 - accuracy: 0.9134 - 2s/epoch - 9ms/step\n",
            "Epoch 160/200\n",
            "244/244 - 2s - loss: 0.3084 - accuracy: 0.9136 - 2s/epoch - 9ms/step\n",
            "Epoch 161/200\n",
            "244/244 - 2s - loss: 0.2987 - accuracy: 0.9161 - 2s/epoch - 9ms/step\n",
            "Epoch 162/200\n",
            "244/244 - 2s - loss: 0.2939 - accuracy: 0.9168 - 2s/epoch - 9ms/step\n",
            "Epoch 163/200\n",
            "244/244 - 2s - loss: 0.2910 - accuracy: 0.9168 - 2s/epoch - 9ms/step\n",
            "Epoch 164/200\n",
            "244/244 - 2s - loss: 0.2898 - accuracy: 0.9158 - 2s/epoch - 9ms/step\n",
            "Epoch 165/200\n",
            "244/244 - 2s - loss: 0.2892 - accuracy: 0.9170 - 2s/epoch - 9ms/step\n",
            "Epoch 166/200\n",
            "244/244 - 2s - loss: 0.2876 - accuracy: 0.9152 - 2s/epoch - 9ms/step\n",
            "Epoch 167/200\n",
            "244/244 - 2s - loss: 0.2869 - accuracy: 0.9172 - 2s/epoch - 9ms/step\n",
            "Epoch 168/200\n",
            "244/244 - 2s - loss: 0.2858 - accuracy: 0.9175 - 2s/epoch - 9ms/step\n",
            "Epoch 169/200\n",
            "244/244 - 2s - loss: 0.2860 - accuracy: 0.9159 - 2s/epoch - 9ms/step\n",
            "Epoch 170/200\n",
            "244/244 - 2s - loss: 0.2847 - accuracy: 0.9168 - 2s/epoch - 9ms/step\n",
            "Epoch 171/200\n",
            "244/244 - 2s - loss: 0.2859 - accuracy: 0.9148 - 2s/epoch - 9ms/step\n",
            "Epoch 172/200\n",
            "244/244 - 2s - loss: 0.2827 - accuracy: 0.9157 - 2s/epoch - 9ms/step\n",
            "Epoch 173/200\n",
            "244/244 - 2s - loss: 0.2800 - accuracy: 0.9170 - 2s/epoch - 9ms/step\n",
            "Epoch 174/200\n",
            "244/244 - 3s - loss: 0.2785 - accuracy: 0.9167 - 3s/epoch - 11ms/step\n",
            "Epoch 175/200\n",
            "244/244 - 2s - loss: 0.2777 - accuracy: 0.9179 - 2s/epoch - 9ms/step\n",
            "Epoch 176/200\n",
            "244/244 - 2s - loss: 0.2813 - accuracy: 0.9150 - 2s/epoch - 9ms/step\n",
            "Epoch 177/200\n",
            "244/244 - 2s - loss: 0.2939 - accuracy: 0.9144 - 2s/epoch - 9ms/step\n",
            "Epoch 178/200\n",
            "244/244 - 2s - loss: 0.3107 - accuracy: 0.9097 - 2s/epoch - 9ms/step\n",
            "Epoch 179/200\n",
            "244/244 - 2s - loss: 0.2940 - accuracy: 0.9153 - 2s/epoch - 9ms/step\n",
            "Epoch 180/200\n",
            "244/244 - 2s - loss: 0.2749 - accuracy: 0.9175 - 2s/epoch - 9ms/step\n",
            "Epoch 181/200\n",
            "244/244 - 2s - loss: 0.2723 - accuracy: 0.9177 - 2s/epoch - 9ms/step\n",
            "Epoch 182/200\n",
            "244/244 - 2s - loss: 0.2715 - accuracy: 0.9162 - 2s/epoch - 9ms/step\n",
            "Epoch 183/200\n",
            "244/244 - 2s - loss: 0.2707 - accuracy: 0.9163 - 2s/epoch - 9ms/step\n",
            "Epoch 184/200\n",
            "244/244 - 2s - loss: 0.2698 - accuracy: 0.9167 - 2s/epoch - 9ms/step\n",
            "Epoch 185/200\n",
            "244/244 - 2s - loss: 0.2689 - accuracy: 0.9152 - 2s/epoch - 9ms/step\n",
            "Epoch 186/200\n",
            "244/244 - 2s - loss: 0.2689 - accuracy: 0.9170 - 2s/epoch - 9ms/step\n",
            "Epoch 187/200\n",
            "244/244 - 2s - loss: 0.2685 - accuracy: 0.9168 - 2s/epoch - 9ms/step\n",
            "Epoch 188/200\n",
            "244/244 - 2s - loss: 0.2688 - accuracy: 0.9155 - 2s/epoch - 9ms/step\n",
            "Epoch 189/200\n",
            "244/244 - 2s - loss: 0.2678 - accuracy: 0.9177 - 2s/epoch - 9ms/step\n",
            "Epoch 190/200\n",
            "244/244 - 2s - loss: 0.2682 - accuracy: 0.9173 - 2s/epoch - 9ms/step\n",
            "Epoch 191/200\n",
            "244/244 - 2s - loss: 0.2672 - accuracy: 0.9170 - 2s/epoch - 9ms/step\n",
            "Epoch 192/200\n",
            "244/244 - 2s - loss: 0.2656 - accuracy: 0.9166 - 2s/epoch - 9ms/step\n",
            "Epoch 193/200\n",
            "244/244 - 2s - loss: 0.2666 - accuracy: 0.9175 - 2s/epoch - 9ms/step\n",
            "Epoch 194/200\n",
            "244/244 - 2s - loss: 0.2673 - accuracy: 0.9153 - 2s/epoch - 9ms/step\n",
            "Epoch 195/200\n",
            "244/244 - 2s - loss: 0.2664 - accuracy: 0.9172 - 2s/epoch - 9ms/step\n",
            "Epoch 196/200\n",
            "244/244 - 2s - loss: 0.2657 - accuracy: 0.9180 - 2s/epoch - 9ms/step\n",
            "Epoch 197/200\n",
            "244/244 - 2s - loss: 0.2641 - accuracy: 0.9167 - 2s/epoch - 9ms/step\n",
            "Epoch 198/200\n",
            "244/244 - 2s - loss: 0.2637 - accuracy: 0.9154 - 2s/epoch - 9ms/step\n",
            "Epoch 199/200\n",
            "244/244 - 2s - loss: 0.2634 - accuracy: 0.9176 - 2s/epoch - 9ms/step\n",
            "Epoch 200/200\n",
            "244/244 - 2s - loss: 0.2631 - accuracy: 0.9170 - 2s/epoch - 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4752c94dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generator(model, tokenizer, current_word, n):\n",
        "  init_word = current_word\n",
        "  sentence = ''\n",
        "\n",
        "  for _ in range(n):\n",
        "    encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
        "    \n",
        "    result = model.predict(encoded, verbose=0)\n",
        "    result = np.array(result, axis=1)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == result:\n",
        "        break\n",
        "\n",
        "    current_word = current_word + ' ' + word\n",
        "\n",
        "    sentence = sentence + ' ' + word\n",
        "\n",
        "  sentence = init_word + sentence\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "WtQwbvveJOE_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, 'i', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrhtGQKfJ22h",
        "outputId": "72f887de-5e5a-456b-ee03-e2ef30c038da"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i feeling of trump aide very labor always korean pompeo families\n"
          ]
        }
      ]
    }
  ]
}