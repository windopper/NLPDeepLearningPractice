{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Character-Level_Nerual_Machine_Translation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCqLPUetlGlZy85TDqRwn6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/windopper/NLPDeepLearningPractice/blob/main/EncoderDecoderUsingRNN/Character_Level_Nerual_Machine_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시퀀스-투-시퀀스(seq2seq)를 사용하여 문자 레벨 기계 번역기 구현해보기"
      ],
      "metadata": {
        "id": "ioB8pZKevQHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "병렬 코퍼스 데이터에 대한 이해와 전처리"
      ],
      "metadata": {
        "id": "OWeaZKMcwmf2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QEzXkKcdvKLD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import urllib3\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "http = urllib3.PoolManager()\n",
        "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = 'fra-eng.zip'\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, filename)\n",
        "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
        "    shutil.copyfileobj(r, out_file)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)"
      ],
      "metadata": {
        "id": "peuX26rgvsS0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
        "del lines['lic']\n",
        "print('전체 샘플의 개수 :',len(lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abP5cBo7vufu",
        "outputId": "72cdd82c-4371-4860-c77c-9b5e5a6c5bdb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 개수 : 192341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = lines.loc[:, 'src':'tar']\n",
        "lines = lines[0:60000]\n",
        "lines.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "nL4x8ISBvxfy",
        "outputId": "b125b7fb-e544-4253-e219-2f25e2e9a91f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ade330bf-a307-4ef1-925d-cffc6e6cf8b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52016</th>\n",
              "      <td>Tom resuscitated Mary.</td>\n",
              "      <td>Tom a réanimé Marie.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21522</th>\n",
              "      <td>Where's your mom?</td>\n",
              "      <td>Où est ta mère ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1754</th>\n",
              "      <td>Do I snore?</td>\n",
              "      <td>Est-ce que je ronfle ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21158</th>\n",
              "      <td>We spoke briefly.</td>\n",
              "      <td>Nous nous sommes brièvement entretenues.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19848</th>\n",
              "      <td>See you tomorrow.</td>\n",
              "      <td>On se voit demain.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48649</th>\n",
              "      <td>I have another sister.</td>\n",
              "      <td>J'ai une autre sœur.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36446</th>\n",
              "      <td>It rained yesterday.</td>\n",
              "      <td>Il a plu hier.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32524</th>\n",
              "      <td>We're all students.</td>\n",
              "      <td>Nous sommes tous étudiants.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44620</th>\n",
              "      <td>This is a real steal.</td>\n",
              "      <td>C'est une vraie bonne affaire.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4356</th>\n",
              "      <td>Are you cold?</td>\n",
              "      <td>Avez-vous froid ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ade330bf-a307-4ef1-925d-cffc6e6cf8b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ade330bf-a307-4ef1-925d-cffc6e6cf8b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ade330bf-a307-4ef1-925d-cffc6e6cf8b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                          src                                       tar\n",
              "52016  Tom resuscitated Mary.                      Tom a réanimé Marie.\n",
              "21522       Where's your mom?                          Où est ta mère ?\n",
              "1754              Do I snore?                    Est-ce que je ronfle ?\n",
              "21158       We spoke briefly.  Nous nous sommes brièvement entretenues.\n",
              "19848       See you tomorrow.                        On se voit demain.\n",
              "48649  I have another sister.                      J'ai une autre sœur.\n",
              "36446    It rained yesterday.                            Il a plu hier.\n",
              "32524     We're all students.               Nous sommes tous étudiants.\n",
              "44620   This is a real steal.            C'est une vraie bonne affaire.\n",
              "4356            Are you cold?                         Avez-vous froid ?"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "시작 심볼과 종료 심볼 추가"
      ],
      "metadata": {
        "id": "y90vIDbdwZ44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines.tar = lines.tar.apply(lambda x : '\\t '+x+' \\n')\n",
        "lines.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "nw0wX78hv6XL",
        "outputId": "b6264f31-2c34-43f1-e8d6-8e60d8730e35"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-93125452-997d-4f89-b49b-a2bd181e228c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21572</th>\n",
              "      <td>Whose turn is it?</td>\n",
              "      <td>\\t À qui le tour ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Run.</td>\n",
              "      <td>\\t Cours ! \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52680</th>\n",
              "      <td>When did you say that?</td>\n",
              "      <td>\\t Quand as-tu dit cela ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36654</th>\n",
              "      <td>Japanese are Asians.</td>\n",
              "      <td>\\t Les Japonais sont des Asiatiques. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6777</th>\n",
              "      <td>Everyone wins.</td>\n",
              "      <td>\\t Tout le monde y gagne. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30242</th>\n",
              "      <td>Is the house ready?</td>\n",
              "      <td>\\t La maison est-elle prête ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52659</th>\n",
              "      <td>What's your shoe size?</td>\n",
              "      <td>\\t Quelle pointure faites-vous ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18720</th>\n",
              "      <td>I still love you.</td>\n",
              "      <td>\\t Je t'aime encore. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54037</th>\n",
              "      <td>Do you know how to ski?</td>\n",
              "      <td>\\t Savez-vous skier ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4732</th>\n",
              "      <td>I admire you.</td>\n",
              "      <td>\\t Je t'admire. \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93125452-997d-4f89-b49b-a2bd181e228c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93125452-997d-4f89-b49b-a2bd181e228c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93125452-997d-4f89-b49b-a2bd181e228c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                           src                                      tar\n",
              "21572        Whose turn is it?                    \\t À qui le tour ? \\n\n",
              "13                        Run.                            \\t Cours ! \\n\n",
              "52680   When did you say that?             \\t Quand as-tu dit cela ? \\n\n",
              "36654     Japanese are Asians.  \\t Les Japonais sont des Asiatiques. \\n\n",
              "6777            Everyone wins.             \\t Tout le monde y gagne. \\n\n",
              "30242      Is the house ready?         \\t La maison est-elle prête ? \\n\n",
              "52659   What's your shoe size?      \\t Quelle pointure faites-vous ? \\n\n",
              "18720        I still love you.                  \\t Je t'aime encore. \\n\n",
              "54037  Do you know how to ski?                 \\t Savez-vous skier ? \\n\n",
              "4732             I admire you.                       \\t Je t'admire. \\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문자 집합 생성"
      ],
      "metadata": {
        "id": "oVoTjMKNwzz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = set()\n",
        "for line in lines.src:\n",
        "  for char in line:\n",
        "    src_vocab.add(char)\n",
        "\n",
        "tar_vocab = set()\n",
        "for line in lines.tar:\n",
        "  for char in line:\n",
        "    tar_vocab.add(char)"
      ],
      "metadata": {
        "id": "MScFltYGwHpa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(src_vocab) + 1\n",
        "tar_vocab_size = len(tar_vocab) + 1\n",
        "print('source 문장의 char 집합 : ', src_vocab_size)\n",
        "print('target 문장의 char 집합 : ', tar_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcj4wzeyw-Gm",
        "outputId": "079c6e1c-bda9-459f-b432-1caa74275f0c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 char 집합 :  80\n",
            "target 문장의 char 집합 :  105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "리스트로 정렬"
      ],
      "metadata": {
        "id": "9J8fXUqIxVR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = sorted(list(src_vocab))\n",
        "tar_vocab = sorted(list(tar_vocab))\n",
        "\n",
        "print(src_vocab[45:75])\n",
        "print(tar_vocab[45:75])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAuotoKCxHcN",
        "outputId": "55f9a3b2-3921-4d9c-f929-b0a95a1c65ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문자에 인덱스 부여"
      ],
      "metadata": {
        "id": "Yodr4adQxhaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "print(src_to_index)\n",
        "print(tar_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbiUbL0MxcqP",
        "outputId": "8e93bce9-e046-484f-d961-7d3f055411ad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, '°': 76, 'é': 77, '’': 78, '€': 79}\n",
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, '\\u2009': 100, '\\u200b': 101, '‘': 102, '’': 103, '\\u202f': 104}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정수 인코딩 진행"
      ],
      "metadata": {
        "id": "JnmTv2cLx2Li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = []\n",
        "\n",
        "for line in lines.src:\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    encoded_line.append(src_to_index[char])\n",
        "  encoder_input.append(encoded_line)\n",
        "print('source 문장의 정수 인코딩 : ', encoder_input[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGhu6xrOxvfe",
        "outputId": "4f5c1122-8849-4766-9dea-131e3bf6faeb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 정수 인코딩 :  [[30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10], [31, 58, 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input = []\n",
        "for line in lines.tar:\n",
        "  decoded_line = []\n",
        "  for char in line:\n",
        "    decoded_line.append(tar_to_index[char])\n",
        "  decoder_input.append(decoded_line)\n",
        "print('target 문장의 정수 인코딩 : ', decoder_input[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCaT8UrdyFE6",
        "outputId": "97c23326-8c39-4b48-ec6f-14c3fa1877b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장의 정수 인코딩 :  [[1, 3, 48, 53, 3, 4, 3, 2], [1, 3, 39, 53, 70, 55, 60, 57, 14, 3, 2], [1, 3, 28, 67, 73, 59, 57, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 14, 3, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측값과 비교하기 위한 실제값 전처리. 시작 심볼에 해당하는 &lt;sos&gt;를 제거"
      ],
      "metadata": {
        "id": "Q8fcOIaDyhJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target = []\n",
        "for line in lines.tar:\n",
        "  timestep = 0\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    if timestep>0:\n",
        "      encoded_line.append(tar_to_index[char])\n",
        "    timestep = timestep + 1\n",
        "  decoder_target.append(encoded_line)\n",
        "print('target 문장 레이블의 정수 인코딩 :', decoder_target[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nyGXuBcySGv",
        "outputId": "203909cd-f617-4955-e5b3-087e6c6674bf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장 레이블의 정수 인코딩 : [[3, 48, 53, 3, 4, 3, 2], [3, 39, 53, 70, 55, 60, 57, 14, 3, 2], [3, 28, 67, 73, 59, 57, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 14, 3, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모든 데이터에 대하여 패딩 작업 수행"
      ],
      "metadata": {
        "id": "QLkXWHWDzc5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "print('source 문장의 최대 길이 : ', max_src_len)\n",
        "print('target 문장의 최대 길이 : ', max_tar_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0llALRBy0kV",
        "outputId": "8d52e796-b365-49a1-e867-6880ba44aace"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 최대 길이 :  23\n",
            "target 문장의 최대 길이 :  76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
      ],
      "metadata": {
        "id": "sniwkET6zt5i"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "문자 단위 번역기임으로 워드 임베딩을 사용하지 않고 원-핫 벡터를 사용"
      ],
      "metadata": {
        "id": "SY3tlb7i0FdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "metadata": {
        "id": "ZeQLtzGh0CkG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "디코더 셀의 입력은 이전 디코더 셀의 출력으로 부터 받지만, 모델의 예측이 다른 방향으로 가는 것을 방지하기 위하여 '교사 강요'라는 방법을 쓴다.\n",
        "decoder_input 값을 새로운 입력으로 사용하여 모델의 예측이 엇나가는 것을 막는다.\n",
        "\n",
        "seq2seq 기계 번역기 훈련시키기"
      ],
      "metadata": {
        "id": "EoKA9eKz0frK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_bpjFHWs0SPo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)\n",
        "\n",
        "# encoder_outputs는 '교사강요' 방법을 사용할 것이기 때문에 여기서는 불필요하다\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs);\n",
        "\n",
        "# LSTM은 바닐라 RNN과는 달리 상태가 두 개이다. 은닉상태와 셀 상태\n",
        "# 자세한 것은 위키독스의 LSTM 파트 참고\n",
        "encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "3IRq1EX-1EIR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "\n",
        "# 디코더에게 은닉 상태, 셀 상태 전달\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy'\n",
        ")\n",
        "\n",
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=40, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bujtOP7d1KyY",
        "outputId": "311cb938-d751-42db-8c48-f77424ecceba"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "750/750 [==============================] - 53s 57ms/step - loss: 0.7527 - val_loss: 0.6642\n",
            "Epoch 2/40\n",
            "750/750 [==============================] - 35s 46ms/step - loss: 0.4572 - val_loss: 0.5326\n",
            "Epoch 3/40\n",
            "750/750 [==============================] - 34s 45ms/step - loss: 0.3814 - val_loss: 0.4715\n",
            "Epoch 4/40\n",
            "750/750 [==============================] - 35s 47ms/step - loss: 0.3393 - val_loss: 0.4345\n",
            "Epoch 5/40\n",
            "750/750 [==============================] - 34s 46ms/step - loss: 0.3108 - val_loss: 0.4114\n",
            "Epoch 6/40\n",
            "750/750 [==============================] - 34s 46ms/step - loss: 0.2903 - val_loss: 0.3925\n",
            "Epoch 7/40\n",
            "750/750 [==============================] - 34s 46ms/step - loss: 0.2743 - val_loss: 0.3807\n",
            "Epoch 8/40\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.2615 - val_loss: 0.3712\n",
            "Epoch 9/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.2506 - val_loss: 0.3647\n",
            "Epoch 10/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.2413 - val_loss: 0.3591\n",
            "Epoch 11/40\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.2330 - val_loss: 0.3559\n",
            "Epoch 12/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.2256 - val_loss: 0.3540\n",
            "Epoch 13/40\n",
            "750/750 [==============================] - 34s 45ms/step - loss: 0.2190 - val_loss: 0.3516\n",
            "Epoch 14/40\n",
            "750/750 [==============================] - 35s 47ms/step - loss: 0.2130 - val_loss: 0.3501\n",
            "Epoch 15/40\n",
            "750/750 [==============================] - 34s 45ms/step - loss: 0.2074 - val_loss: 0.3494\n",
            "Epoch 16/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.2022 - val_loss: 0.3490\n",
            "Epoch 17/40\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1974 - val_loss: 0.3515\n",
            "Epoch 18/40\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.1930 - val_loss: 0.3507\n",
            "Epoch 19/40\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1888 - val_loss: 0.3525\n",
            "Epoch 20/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1848 - val_loss: 0.3550\n",
            "Epoch 21/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1810 - val_loss: 0.3538\n",
            "Epoch 22/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1775 - val_loss: 0.3566\n",
            "Epoch 23/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1742 - val_loss: 0.3575\n",
            "Epoch 24/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1711 - val_loss: 0.3608\n",
            "Epoch 25/40\n",
            "750/750 [==============================] - 34s 45ms/step - loss: 0.1679 - val_loss: 0.3645\n",
            "Epoch 26/40\n",
            "750/750 [==============================] - 37s 49ms/step - loss: 0.1651 - val_loss: 0.3649\n",
            "Epoch 27/40\n",
            "750/750 [==============================] - 36s 47ms/step - loss: 0.1623 - val_loss: 0.3658\n",
            "Epoch 28/40\n",
            "750/750 [==============================] - 35s 46ms/step - loss: 0.1596 - val_loss: 0.3699\n",
            "Epoch 29/40\n",
            "750/750 [==============================] - 35s 47ms/step - loss: 0.1571 - val_loss: 0.3725\n",
            "Epoch 30/40\n",
            "750/750 [==============================] - 36s 47ms/step - loss: 0.1548 - val_loss: 0.3754\n",
            "Epoch 31/40\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.1524 - val_loss: 0.3782\n",
            "Epoch 32/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1502 - val_loss: 0.3795\n",
            "Epoch 33/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1480 - val_loss: 0.3820\n",
            "Epoch 34/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1459 - val_loss: 0.3853\n",
            "Epoch 35/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1440 - val_loss: 0.3894\n",
            "Epoch 36/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1421 - val_loss: 0.3915\n",
            "Epoch 37/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1403 - val_loss: 0.3933\n",
            "Epoch 38/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1384 - val_loss: 0.3967\n",
            "Epoch 39/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1368 - val_loss: 0.3990\n",
            "Epoch 40/40\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1352 - val_loss: 0.4026\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd68343ee90>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기계 번역기 동작시키기\n",
        "\n",
        "전체적인 번역 동작 원리 정리:\n",
        "\n",
        "<ol>\n",
        "<li>\n",
        "번역하고자 하는 입력문장이 인코더에 들어가서 은닉 상태와 셀 상태를 얻음\n",
        "</li>\n",
        "<li>\n",
        "상태와 &lt;SOS&gt;에 해당하는 '\\t'를 디코더로 보냄\n",
        "</li>\n",
        "<li>\n",
        "디코더가 &lt;EOS&gt;에 해당하는 '\\n'이 나올 때까지 다음 문자를 예측하는 행동을 반복\n",
        "</li>\n",
        "</ol>"
      ],
      "metadata": {
        "id": "p4JQtWDA3QFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 정의\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
        "\n",
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xepou2sc238_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
      ],
      "metadata": {
        "id": "WeDGuFPD8ISj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "  target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "  target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  # stop_condition이 True가 될 때까지 루프 반복\n",
        "  while not stop_condition:\n",
        "    # 이전 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "    decoded_sentence += sampled_char\n",
        "    \n",
        "    # <EOS>에 도달하거나 최대 길이를 넘으면 중단\n",
        "    if(sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
        "      stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence\n",
        "\n"
      ],
      "metadata": {
        "id": "XfETszxH8PLp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]: # 입력 문장의 인덱스\n",
        "  input_seq = encoder_input[seq_index:seq_index+1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * \"-\")\n",
        "  print('입력 문장 :', lines.src[seq_index])\n",
        "  print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "  print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQBmcggx99IG",
        "outputId": "2133db14-d0fe-4177-e64b-179cb9ee3773"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n",
            "입력 문장 : Hi.\n",
            "정답 문장: Salut ! \n",
            "번역 문장: Salut. \n",
            "-----------------------------------\n",
            "입력 문장 : I see.\n",
            "정답 문장: Aha. \n",
            "번역 문장: Je suis en train de manger. \n",
            "-----------------------------------\n",
            "입력 문장 : Hug me.\n",
            "정답 문장: Serrez-moi dans vos bras ! \n",
            "번역 문장: Serre-moi dans tes bras ! \n",
            "-----------------------------------\n",
            "입력 문장 : Help me.\n",
            "정답 문장: Aidez-moi. \n",
            "번역 문장: Aide-moi. \n",
            "-----------------------------------\n",
            "입력 문장 : I am sure.\n",
            "정답 문장: Je suis sûr. \n",
            "번역 문장: Je suis tendu. \n"
          ]
        }
      ]
    }
  ]
}