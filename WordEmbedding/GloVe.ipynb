{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 글로브(GloVe)\n",
    "reference https://wikidocs.net/22885"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kwon_notebook\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 20 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n"
     ]
    }
   ],
   "source": [
    "from glove import Corpus, Glove\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from lxml import etree\n",
    "\n",
    "corpus = Corpus()\n",
    "\n",
    "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF-8')\n",
    "target_text = etree.parse(targetXML)\n",
    "\n",
    "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져옴\n",
    "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
    "\n",
    "# 정규 표현식의 sub 모듈을 통하여 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
    "# 해당 코드는 괄호로 구성된 내용을 제거.\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
    "\n",
    "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n",
    "sent_text = sent_tokenize(content_text)\n",
    "\n",
    "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "    normalized_text.append(tokens)\n",
    "\n",
    "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행\n",
    "result = [word_tokenize(sentence) for sentence in normalized_text]\n",
    "\n",
    "# 훈련 데이터로부터 GloVe에서 사용할 동시 등장 행렬 생성\n",
    "corpus.fit(result, window=5)\n",
    "glove = Glove(no_components=100, learning_rate=0.05)\n",
    "\n",
    "# 학습에 이용할 스레드의 개수는 4로 설정, 에포크는 20.\n",
    "glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "학습이 완료됨"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.9640719879419696), ('guy', 0.8818836374295559), ('girl', 0.8765638951120126), ('kid', 0.8439685808636391)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar('man'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('girl', 0.9399887205245915), ('woman', 0.8554426843688894), ('man', 0.8401107819984592), ('kid', 0.8361809112584776)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar('boy'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('harvard', 0.8960422570238128), ('mit', 0.8624370326163452), ('stanford', 0.8439557706470072), ('cambridge', 0.8421337766106579)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar('university'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('air', 0.8458107397242466), ('clean', 0.8426650677921109), ('fresh', 0.831751190658794), ('food', 0.8155714495256721)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar('water'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chemistry', 0.8946326719013055), ('economics', 0.8870988871967064), ('mathematics', 0.8665281526010955), ('beauty', 0.8646533561066604)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"physics\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tissue', 0.846216604698914), ('nerve', 0.8193104189398185), ('channel', 0.7650735834396339), ('skeletal', 0.7645080426800865)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"muscle\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}